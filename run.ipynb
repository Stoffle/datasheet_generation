{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU automatically detected. Setting SETTINGS.GPU to 0, and SETTINGS.NJOBS to cpu_count.\n"
     ]
    }
   ],
   "source": [
    "from baynet import DAG, metrics\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from cdt.causality import graph\n",
    "from cdt.utils import dagify_min_edge\n",
    "import pandas as pd\n",
    "from typing import List, Optional, Tuple, Hashable, Dict\n",
    "from itertools import product\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cdt_to_baynet(cpdag: nx.DiGraph, columns: List[str]) -> DAG:\n",
    "    adj_matrix = np.array(nx.adj_matrix(cpdag).todense())\n",
    "    graph = baynet.DAG.from_amat(adj_matrix, columns)\n",
    "    return graph\n",
    "\n",
    "def PC(data: pd.DataFrame, ci_test: str = \"discrete\") -> DAG:\n",
    "    \"\"\"\n",
    "    Wrap of the CDT predict function of the PC algorithm. Return a learnt DAG from data.\n",
    "\n",
    "    :param data: The data which the structure will be learnt with (Pandas.DataFrame)\n",
    "    :param ci_test: The (str) argument specifying which Conditional Indep. test to use\n",
    "    :return: A learnt DAG (BayNet DAG)\n",
    "    \"\"\"\n",
    "    pc = graph.PC(CItest=ci_test, verbose=False)\n",
    "    cpdag = pc_alg.predict(data)\n",
    "    dag = self.cdt.utils.dagify_min_edge(cpdag)\n",
    "    return _cdt_to_baynet(dag, list(data.columns))\n",
    "\n",
    "def GES(data: pd.DataFrame, score: str = \"int\") -> DAG:\n",
    "    \"\"\"\n",
    "    Wrap of the CDT predict function of the GES algorithm. Return a learnt DAG from data.\n",
    "\n",
    "    :param data: The data which the structure will be learnt with (Pandas.DataFrame)\n",
    "    :param score: The (str) argument specifying which score function to use\n",
    "    :return: A learnt DAG (BayNet DAG)\n",
    "    \"\"\"\n",
    "    pc = graph.GES(score=score, verbose=False)\n",
    "    cpdag = pc_alg.predict(data)\n",
    "    dag = self.cdt.utils.dagify_min_edge(cpdag)\n",
    "    return _cdt_to_baynet(dag, list(data.columns))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_combinations_odds_ratio(\n",
    "    model: DAG,\n",
    "    target: Optional[str] = None,\n",
    "    data: Optional[pd.DataFrame] = None,\n",
    ") -> Tuple[dict, str]:\n",
    "    \"\"\"\n",
    "    Get a dictionary object containing all possible odds ratios on a target.\n",
    "\n",
    "    :param model: A DAG object on which to calculate the odds ratios\n",
    "    :param target: A str specifying the target node\n",
    "    :return: A dictionary of odds ratios, with tuple keys\n",
    "    \"\"\"\n",
    "    odds_ratio_dict = dict()\n",
    "\n",
    "    if target is not None and target not in list(map(str, model.nodes)):\n",
    "        raise ValueError(f'\"{target}\" node not found in model.')\n",
    "\n",
    "    if target is None:\n",
    "        target = get_target_variable(model)\n",
    "\n",
    "    target_levels = model.get_node(target)[\"levels\"]\n",
    "    target_reference = target_levels[0]\n",
    "\n",
    "    valid_nodes = (\n",
    "        model.nodes - set(model.get_descendants(target, only_children=True)[\"name\"]) - {target}\n",
    "    )\n",
    "    for target_target in target_levels[1:]:\n",
    "        for evidence in valid_nodes:\n",
    "            evidence_levels = model.get_node(evidence)[\"levels\"]\n",
    "            evidence_reference = evidence_levels[0]\n",
    "\n",
    "            for evidence_target in evidence_levels[1:]:\n",
    "                or_key = (\n",
    "                    target,\n",
    "                    str(target_reference),\n",
    "                    str(target_target),\n",
    "                    evidence,\n",
    "                    str(evidence_reference),\n",
    "                    str(evidence_target),\n",
    "                )\n",
    "                or_result = odds_ratio(\n",
    "                    model,\n",
    "                    target,\n",
    "                    evidence,\n",
    "                    target_reference,\n",
    "                    target_target,\n",
    "                    evidence_reference,\n",
    "                    evidence_target,\n",
    "                    data=data,\n",
    "                )\n",
    "                if or_result is not None:\n",
    "                    odds_ratio_dict[or_key] = or_result\n",
    "\n",
    "    return odds_ratio_dict, target\n",
    "\n",
    "def odds_ratio(\n",
    "    model: DAG,\n",
    "    target: str,\n",
    "    evidence: str,\n",
    "    target_reference_level: str,\n",
    "    target_target_level: str,\n",
    "    evidence_reference_level: str,\n",
    "    evidence_target_level: str,\n",
    "    data: Optional[pd.DataFrame] = None,\n",
    ") -> Tuple[np.float64, np.float64, np.float64]:\n",
    "    \"\"\"\n",
    "    Produce odds ratios for a target node given some evidence.\n",
    "\n",
    "    Does so via CPD manipulation/propagation, as opposed to network sampling.\n",
    "\n",
    "    :param data:\n",
    "    :param model: DAG with structure and CPDs defined.\n",
    "    :param target: The target node to estimate the effect on\n",
    "    :param target_target_level: The target level of the target node\n",
    "    :param target_reference_level: The reference level of the target node\n",
    "    :param evidence: The node which is being intervened on (evidence provided for)\n",
    "    :param evidence_target_level: The target level for the evidence node\n",
    "    :param evidence_reference_level: The reference level for the evidence node\n",
    "\n",
    "    :return: the estimated odds ratio\n",
    "    :type: numpy.float64\n",
    "    \"\"\"\n",
    "    #  If the evidence node is a direct descendent of the target node then\n",
    "    #  intervening on it will remove the latter from the graph.\n",
    "    if evidence in model.get_descendants(target, only_children=True)[\"name\"]:\n",
    "        warnings.warn(\n",
    "            f\"Odds ratio cannot be computed as evidence node '{evidence}' is a direct descendent \"\n",
    "            f\"of target node '{target}'\"\n",
    "        )\n",
    "        dummy = cast(np.float64, 1)\n",
    "        return dummy, dummy, dummy\n",
    "    target_reference_idx = int(target_reference_level)\n",
    "    target_target_idx = int(target_target_level)\n",
    "    return _static_intervention(\n",
    "        model=model,\n",
    "        target=target,\n",
    "        evidence=evidence,\n",
    "        evidence_level=str(evidence_reference_level),\n",
    "        target_level=str(evidence_target_level),\n",
    "        target_target_idx=target_target_idx,\n",
    "        target_reference_idx=target_reference_idx,\n",
    "        data=data,\n",
    "    )\n",
    "    \n",
    "def _static_intervention(\n",
    "    model: DAG,\n",
    "    target: str,\n",
    "    evidence: str,\n",
    "    evidence_level: Hashable,\n",
    "    target_level: Hashable,\n",
    "    target_target_idx: int,\n",
    "    target_reference_idx: int,\n",
    "    data: Optional[pd.DataFrame],\n",
    ") -> Tuple[np.float64, np.float64, np.float64]:\n",
    "    \"\"\"\n",
    "    Get distribution of the `target` node after intervening on the evidence node's evidence_level.\n",
    "\n",
    "    :param model: DAG to perform intervention on; with structure and CPDs defined.\n",
    "    :param target: node to assess interventional outcome\n",
    "    :param evidence: node to perform intervention on\n",
    "    :param evidence_level: level of `evidence` node to perform intervention on\n",
    "    :return: resultant distribution of the `target` node after propagating intervention.\n",
    "    \"\"\"\n",
    "    if evidence not in model.nodes:\n",
    "        return 1, 1, 1\n",
    "    reference_model = model.mutilate(evidence, str(evidence_level))\n",
    "    target_model = model.mutilate(evidence, str(target_level))\n",
    "    n_data = 1 if data is None else len(data)\n",
    "    target_dist = _propogate_probability(target_model, target) * n_data\n",
    "    reference_dist = _propogate_probability(reference_model, target) * n_data\n",
    "    result = (target_dist[target_target_idx] / target_dist[target_reference_idx]) / (\n",
    "        reference_dist[target_target_idx] / reference_dist[target_reference_idx]\n",
    "    )\n",
    "    standard_error = np.sqrt(\n",
    "        1 / target_dist[target_target_idx]\n",
    "        + 1 / target_dist[target_reference_idx]\n",
    "        + 1 / reference_dist[target_target_idx]\n",
    "        + 1 / reference_dist[target_reference_idx]\n",
    "    )\n",
    "    upper = np.exp(np.log(result) + 1.96 * standard_error)\n",
    "    lower = np.exp(np.log(result) - 1.96 * standard_error)\n",
    "    if data is None:\n",
    "        return result, result, result\n",
    "    return result, upper, lower\n",
    "\n",
    "def _propogate_probability(model: DAG, target: str) -> np.ndarray:\n",
    "    accumulated_probs: Dict[str, np.ndarray] = dict()\n",
    "\n",
    "    for node in _get_resolution_order(model):\n",
    "\n",
    "        # Get CPD of curr node\n",
    "        node_cpd = model.get_node(node)[\"CPD\"].array\n",
    "        ordered_parent_nodes = model.get_node(node)[\"CPD\"].parents\n",
    "\n",
    "        # Init result distribution\n",
    "        result_dist = node_cpd\n",
    "\n",
    "        # If node has parents, perform accumulation step\n",
    "        if ordered_parent_nodes:\n",
    "            for parent_node in reversed(ordered_parent_nodes):\n",
    "                result_dist = accumulated_probs[parent_node].dot(result_dist)\n",
    "\n",
    "        accumulated_probs[node] = result_dist\n",
    "    return accumulated_probs[target]\n",
    "\n",
    "def _classify_or(odds_ratio_result: Tuple[float, float, float]) -> str:\n",
    "    odds_ratio, upper, lower = odds_ratio_result\n",
    "    if odds_ratio > 1:\n",
    "        if upper > 1 and lower > 1:\n",
    "            return \"D\"\n",
    "    if odds_ratio < 1:\n",
    "        if upper < 1 and lower < 1:\n",
    "            return \"P\"\n",
    "    return \"N\"\n",
    "\n",
    "def _pcor(\n",
    "    true_ors: Dict[str, Tuple[float, float, float]],\n",
    "    learnt_ors: Dict[str, Tuple[float, float, float]],\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Calculate the PCOR (prop of correct odds ratios) given two dicts of odds ratios.\n",
    "\n",
    "    @param true_ors: Dictionary of true odds ratios (or_key, or)\n",
    "    @param learnt_ors: Dictionary of learnt odds ratios (or_key, or)\n",
    "\n",
    "    @return: the proportion of correct odds ratios\n",
    "    \"\"\"\n",
    "    hamming = 0\n",
    "    for k, v in true_ors.items():\n",
    "        true_or_class = _classify_or(v)\n",
    "        learnt_or_class = _classify_or(learnt_ors[k])\n",
    "        if true_or_class != learnt_or_class:\n",
    "            hamming += 1\n",
    "    return 1 - (hamming / len(true_ors.keys()))\n",
    "\n",
    "\n",
    "def calculate_pcor(true_bn: DAG, learnt_bn: DAG):\n",
    "    true_ors, target = all_combinations_odds_ratio(true_bn)\n",
    "    learnt_ors, _ = all_combinations_odds_ratio(learnt_bn, target)\n",
    "    return _pcor(true_ors=true_ors, learnt_ors=learnt_ors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = list(range(1, 2)) # 1 -> 10\n",
    "structure_types = [partial(DAG.forest_fire, fw_prob=0.5), DAG.barabasi_albert] # structure type functions\n",
    "variables = [10]\n",
    "samples = [500]\n",
    "alphas = [6.0]\n",
    "max_levels = [4]\n",
    "\n",
    "algorithms = [PC, GES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Call errored, is R available ?\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'Rscript'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3d34993bf17d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# --------- Learn BN ---------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Learn Structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mlearnt_dag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Learn Parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mlearnt_dag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfer_levels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-87f30ae1f843>\u001b[0m in \u001b[0;36mPC\u001b[0;34m(data, ci_test)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mlearnt\u001b[0m \u001b[0mDAG\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBayNet\u001b[0m \u001b[0mDAG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \"\"\"\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mpc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCItest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mci_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mcpdag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpc_alg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mdag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdagify_min_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpdag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ds/lib/python3.8/site-packages/cdt/causality/graph/PC.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, CItest, method_indep, alpha, njobs, verbose)\u001b[0m\n\u001b[1;32m    173\u001b[0m                  njobs=None, verbose=None):\n\u001b[1;32m    174\u001b[0m         \u001b[0;34m\"\"\"Init the model and its available arguments.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mRPackages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpcalg\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mRPackages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkpcalg\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mRPackages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRCIT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             raise ImportError(\"R Package (k)pcalg/RCIT is not available. \"\n\u001b[1;32m    177\u001b[0m                               \u001b[0;34m\"RCIT has to be installed from \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ds/lib/python3.8/site-packages/cdt/utils/R.py\u001b[0m in \u001b[0;36m__getattribute__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'init'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mavailability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_R_package\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavailability\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mavailability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ds/lib/python3.8/site-packages/cdt/utils/R.py\u001b[0m in \u001b[0;36mcheck_R_package\u001b[0;34m(self, package)\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpackage\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mavailable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \"\"\"\n\u001b[0;32m--> 146\u001b[0;31m         test_package = not bool(launch_R_script(Path(\"{}/R_templates/test_import.R\".format(os.path.dirname(os.path.realpath(__file__)))),\n\u001b[0m\u001b[1;32m    147\u001b[0m                                                      {\"{package}\": package}, verbose=True))\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtest_package\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ds/lib/python3.8/site-packages/cdt/utils/R.py\u001b[0m in \u001b[0;36mlaunch_R_script\u001b[0;34m(template, arguments, output_function, verbose, debug)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"R Call errored, is R available ?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ds/lib/python3.8/site-packages/cdt/utils/R.py\u001b[0m in \u001b[0;36mlaunch_R_script\u001b[0;34m(template, arguments, output_function, verbose, debug)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m             output = subprocess.call([str(rpath), \"--vanilla\", str(scriptpath)],\n\u001b[0m\u001b[1;32m    193\u001b[0m                                     \u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVNULL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                                     stderr=subprocess.DEVNULL)\n",
      "\u001b[0;32m~/miniconda3/envs/ds/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ls\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-l\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \"\"\"\n\u001b[0;32m--> 340\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ds/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    852\u001b[0m                             encoding=encoding, errors=errors)\n\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 854\u001b[0;31m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[1;32m    855\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m                                 \u001b[0mstartupinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreationflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ds/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1700\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0merrno_num\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1701\u001b[0m                         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1702\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1703\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'Rscript'"
     ]
    }
   ],
   "source": [
    "columns = [\"Trial\", \"Structure Type\", \"N_Variables\", \"N_Samples\", \"Alpha\", \"Max_Level\",  \"Algorithm\", \"Precision\", \"Recall\", \"V_Structure_Precision\", \"V_Structure_Recall\", \"PCOR\"]\n",
    "results = []\n",
    "\n",
    "for trial, structure_type, variable, sample, alpha, max_level, algorithm in product(*[trials, structure_types, variables, samples, alphas, max_levels, algorithms]):\n",
    "    # ---------  Create Data ------------\n",
    "    dag = structure_type(variable, seed=trial)\n",
    "    dag.generate_discrete_parameters(alpha=alpha, min_levels=2, max_levels=max_level, seed=trial)\n",
    "    data = dag.sample(sample)\n",
    "    # --------- Learn BN ---------------\n",
    "    # Learn Structure\n",
    "    learnt_dag = algorithm(data)\n",
    "    # Learn Parameters\n",
    "    learnt_dag.estimate_parameters(data, infer_levels=True)\n",
    "    # -------- Calculate Metrics -------------\n",
    "    # Skeleton\n",
    "    precision = metrics.precision(dag, learnt_dag, skeleton=True)\n",
    "    recall = metrics.recall(dag, learnt_dag, skeleton=True)\n",
    "    # V Structures\n",
    "    v_precision = metrics.v_precision(dag, learnt_dag)\n",
    "    v_recall = metrics.v_recall(dag, learnt_dag)\n",
    "    # PCOR\n",
    "    pcor = calculate_pcor(dag, learnt_dag)\n",
    "    results.append([trial, structure_type, variable, sample, alpha, max_level, algorithm, precision, recall, v_precision, v_recall, pcor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
